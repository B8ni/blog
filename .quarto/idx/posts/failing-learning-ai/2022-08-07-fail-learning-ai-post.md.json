{"title":"Learning AI And Failing Miserably","markdown":{"yaml":{"toc":true,"layout":"post","description":"A minimal guide of failing learning AI.","author":"Francesco Bottoni","date":"08/07/2022","categories":["fastai"],"title":"Learning AI And Failing Miserably"},"headingText":"Why another blog post?","containsRefs":false,"markdown":"\n\n![](fail-learning.png \"Latest full productivity dekstop setup\")\n\nI told you, you had the wrong guy. Anyway, I'll try to answer.\n\nInternet is a fantastic place, you are plugged into a reality where you can learn whatever you want, whenever you want and at you pace.\n\nWhat I didn't find yet - on web2.0 - is **how to fail**. How to fail programmatically, periodically and frequently. As you can image, I failed a lot and **hope to keep failing at high rate**. \n\nFor me, failing is the essence of learning, the essence of success. The Lhumann's indicator [^1] of productivity was permanent notes produced per day. The Bottoni's indicator [^2] of success is a simple counter of failings: greater the better.  \n \nEverything started long time ago, maybe 6 years ago. I was trying to learning Machine Learning the old way:\n1. collected all theoretical books;\n2. collected all theoretical courses;\n3. started the journey;\n4. felt uncomfortable;\n5. stopped;\n6. and repeat the process with a slightly different theoretical book and course.\n\nThat's guided me here. \n\n**5 months ago I restarted again**. The approach to Machine Learning was gradually different and this seems to be very efficient and effective.\n\nI followed [FastAI course](https://course.fast.ai/). In one week I completed all lectures and developed a simple system:\n- a box classifier which identified the kind of box with an accuracy of 97%;\n- a web app, which took a picture, sent it to the model and showed the result;\n- everything deployed in test environment.\n\nHope to show it as soon as my current company will make it possible.\n\nIt was funny, I accomplished more in that week then in 6 years of try and fail. **But everything died again**.\n\nI got overwhelmed at work. It pushed me to say goodbye to Machine Learning. Another KO.\nYou know, when something really interesting you, one day you succeed. **That day is not today**.\n\nAfter other 5 months, today, I'm back to the mean. To the normality [^3]. I understood that life is not easy and is not linear.\nAt the time I'm writing both my sons got Covid19, high fever, zero sleep.\nI understood to embrace those things, the gifts that life give to us [^4]. \n\nI'm ready to start again, from chapter 0.\n\n## What's my next step?\nI restarted ML journey and I'm happy.\n\nDuring those years full of failures, I sharpened my skills, where I improved a lot, I think.\nFrom note taking to programming. From learning to memorizing. All is summarized in: be more dynamic and less static.\n\nLet me pretend, for a moment, that I will accomplish the following steps.\n\nTo be able to mastering Machine Learning with FastAI approach I need to be a practitioner. To be a practitioner a have to do lots practice. To do lots practice a have to spend extra hours. To be able to spend extra hours I have to be motivated. To be motivated I have to be persistent. To be persistent I have to enjoy it.\n\nThat's the chaining rule of the heaven.\n\n> I listen to everything on 1x speed. I admire all you folks that do 1.5x or 2x, but my brain needs time to process the ideas. Sometimes I pause the podcast/audiobook & just reflect on a single sentence for a while. I used to think I need to improve this but now I just accept it.\n\nI'm happy to read this from [Lex Fridman](https://twitter.com/lexfridman/status/1555957433578790915). It means I have to watch Jeremy at 0.5x divided by few tens speed.\n\nThe approach to learning, as said before, seems working. So that's what I'll do:\n1. Review last notes, if there's something\n2. Watch lecture, first iteration. All in one breath\n3. Watch lecture, second iteration. Pausing as needed, experimenting, exploring and building (lots of -ing)\n4. Going through FastAI book, kaggle notes and random links [^5]\n5. Do questionnaire and find weakness\n6. Focus on a project, only one. Do it well\n\nThat's wonderful approach doesn't come from my neurons but are suggested by [Radek Osmulski's book](https://www.goodreads.com/book/show/58213068-meta-learning) and [Jeremy Howard tips](https://www.youtube.com/watch?v=gGxe2mN3kAg). **Yes, it's strange, I bought a book. I'm not used to**.\n\nAdditional and personal trick to force me studying is **live streaming my session study**. **Embarrassing** and funny moment will face.\n\n**Deadline:** end of August 2022.\n\n**I can infinitely try to learn ML and get a finite result, as per [Zeno's Paradox](https://en.wikipedia.org/wiki/Zeno%27s_paradoxes).**\n\nI'll keep you updated.\n\nNow let's start. **Again**.\n\n---\n\n[^1]: Luhmann wrote prolifically, with more than 70 books and nearly 400 scholarly articles published on a variety of subjects\n[^2]: Me and I wrote only this blog post\n[^3]: Standard deviation equals to zero\n[^4]: Scientists defined it as Entropy \n[^5]: Also known as [syntopic](https://notes.andymatuschak.org/z4AgLtg4p63DZdY3p3aTbfR7p8t1gzEL7FHYk) reading\n","srcMarkdownNoYaml":"\n\n![](fail-learning.png \"Latest full productivity dekstop setup\")\n\n## Why another blog post?\nI told you, you had the wrong guy. Anyway, I'll try to answer.\n\nInternet is a fantastic place, you are plugged into a reality where you can learn whatever you want, whenever you want and at you pace.\n\nWhat I didn't find yet - on web2.0 - is **how to fail**. How to fail programmatically, periodically and frequently. As you can image, I failed a lot and **hope to keep failing at high rate**. \n\nFor me, failing is the essence of learning, the essence of success. The Lhumann's indicator [^1] of productivity was permanent notes produced per day. The Bottoni's indicator [^2] of success is a simple counter of failings: greater the better.  \n \nEverything started long time ago, maybe 6 years ago. I was trying to learning Machine Learning the old way:\n1. collected all theoretical books;\n2. collected all theoretical courses;\n3. started the journey;\n4. felt uncomfortable;\n5. stopped;\n6. and repeat the process with a slightly different theoretical book and course.\n\nThat's guided me here. \n\n**5 months ago I restarted again**. The approach to Machine Learning was gradually different and this seems to be very efficient and effective.\n\nI followed [FastAI course](https://course.fast.ai/). In one week I completed all lectures and developed a simple system:\n- a box classifier which identified the kind of box with an accuracy of 97%;\n- a web app, which took a picture, sent it to the model and showed the result;\n- everything deployed in test environment.\n\nHope to show it as soon as my current company will make it possible.\n\nIt was funny, I accomplished more in that week then in 6 years of try and fail. **But everything died again**.\n\nI got overwhelmed at work. It pushed me to say goodbye to Machine Learning. Another KO.\nYou know, when something really interesting you, one day you succeed. **That day is not today**.\n\nAfter other 5 months, today, I'm back to the mean. To the normality [^3]. I understood that life is not easy and is not linear.\nAt the time I'm writing both my sons got Covid19, high fever, zero sleep.\nI understood to embrace those things, the gifts that life give to us [^4]. \n\nI'm ready to start again, from chapter 0.\n\n## What's my next step?\nI restarted ML journey and I'm happy.\n\nDuring those years full of failures, I sharpened my skills, where I improved a lot, I think.\nFrom note taking to programming. From learning to memorizing. All is summarized in: be more dynamic and less static.\n\nLet me pretend, for a moment, that I will accomplish the following steps.\n\nTo be able to mastering Machine Learning with FastAI approach I need to be a practitioner. To be a practitioner a have to do lots practice. To do lots practice a have to spend extra hours. To be able to spend extra hours I have to be motivated. To be motivated I have to be persistent. To be persistent I have to enjoy it.\n\nThat's the chaining rule of the heaven.\n\n> I listen to everything on 1x speed. I admire all you folks that do 1.5x or 2x, but my brain needs time to process the ideas. Sometimes I pause the podcast/audiobook & just reflect on a single sentence for a while. I used to think I need to improve this but now I just accept it.\n\nI'm happy to read this from [Lex Fridman](https://twitter.com/lexfridman/status/1555957433578790915). It means I have to watch Jeremy at 0.5x divided by few tens speed.\n\nThe approach to learning, as said before, seems working. So that's what I'll do:\n1. Review last notes, if there's something\n2. Watch lecture, first iteration. All in one breath\n3. Watch lecture, second iteration. Pausing as needed, experimenting, exploring and building (lots of -ing)\n4. Going through FastAI book, kaggle notes and random links [^5]\n5. Do questionnaire and find weakness\n6. Focus on a project, only one. Do it well\n\nThat's wonderful approach doesn't come from my neurons but are suggested by [Radek Osmulski's book](https://www.goodreads.com/book/show/58213068-meta-learning) and [Jeremy Howard tips](https://www.youtube.com/watch?v=gGxe2mN3kAg). **Yes, it's strange, I bought a book. I'm not used to**.\n\nAdditional and personal trick to force me studying is **live streaming my session study**. **Embarrassing** and funny moment will face.\n\n**Deadline:** end of August 2022.\n\n**I can infinitely try to learn ML and get a finite result, as per [Zeno's Paradox](https://en.wikipedia.org/wiki/Zeno%27s_paradoxes).**\n\nI'll keep you updated.\n\nNow let's start. **Again**.\n\n---\n\n[^1]: Luhmann wrote prolifically, with more than 70 books and nearly 400 scholarly articles published on a variety of subjects\n[^2]: Me and I wrote only this blog post\n[^3]: Standard deviation equals to zero\n[^4]: Scientists defined it as Entropy \n[^5]: Also known as [syntopic](https://notes.andymatuschak.org/z4AgLtg4p63DZdY3p3aTbfR7p8t1gzEL7FHYk) reading\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"markdown"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"output-file":"2022-08-07-fail-learning-ai-post.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.433","theme":"cosmo","title-block-banner":true,"layout":"post","description":"A minimal guide of failing learning AI.","author":"Francesco Bottoni","date":"08/07/2022","categories":["fastai"],"title":"Learning AI And Failing Miserably"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}